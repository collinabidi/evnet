{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "def load_cifar10_data(img_rows, img_cols, nb_train_samples=1000,nb_valid_samples=200):\n",
    "\n",
    "    # Load cifar10 training and validation sets\n",
    "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
    "\n",
    "    # Resize trainging images\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        X_train = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "    else:\n",
    "        X_train = np.array([cv2.resize(np.divide(np.dot(img[...,:3],[0.2989, 0.5870, 0.1140]),255), (img_rows,img_cols)) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(np.divide(np.dot(img[...,:3],[0.2989, 0.5870, 0.1140]),255), (img_rows,img_cols)) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "\n",
    "    # Transform targets to keras compatible format\n",
    "    Y_train = np_utils.to_categorical(Y_train[:nb_train_samples], num_classes)\n",
    "    Y_valid = np_utils.to_categorical(Y_valid[:nb_valid_samples], num_classes)\n",
    "\n",
    "    return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cols,img_rows = 32,32\n",
    "\n",
    "# load 3000 training samples and 500 validation samples\n",
    "X_train, Y_train, X_valid, Y_valid = load_cifar10_data(img_rows, img_cols, \n",
    "                                                       nb_train_samples=3000,nb_valid_samples=500)\n",
    "\n",
    "Y_train,Y_valid = np.array([np.argmax(i) for i in Y_train]).astype(int),\n",
    "    np.array([np.argmax(i) for i in Y_valid])\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Y_train'] = pd.Series(Y_train.astype(int))\n",
    "df['Y_valid'] = pd.Series(Y_valid.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Y_valid[0].astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
