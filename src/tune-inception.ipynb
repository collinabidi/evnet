{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://flyyufelix.github.io/2016/10/08/fine-tuning-in-keras-part2.html\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cifar10 data\n",
    "nb_train_samples = 3000 # 3000 training samples\n",
    "nb_valid_samples = 100 # 100 validation samples\n",
    "num_classes = 10\n",
    "\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_classes = 10\n",
    "\n",
    "def load_cifar10_data(img_rows, img_cols):\n",
    "    # Load cifar10 training and validation sets\n",
    "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
    "\n",
    "    # Resize trainging images\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        X_train = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "    else:\n",
    "        X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "\n",
    "    # Transform targets to keras compatible format\n",
    "    Y_train = np_utils.to_categorical(Y_train[:nb_train_samples], num_classes)\n",
    "    Y_valid = np_utils.to_categorical(Y_valid[:nb_valid_samples], num_classes)\n",
    "\n",
    "    return X_train, Y_train, X_valid, Y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# HELPER FUNCTIONS #\n",
    "# 1) decodes the algorithm solution to get hyperparameters\n",
    "# 2) trains the LSTM model, calculates fitness function (using RMSE) on validation set and returns fitness score\n",
    "def train_evaluate(ga_individual_solution):   \n",
    "    # Decode individual solution to get actual parameters\n",
    "    window_size_bits = BitArray(ga_individual_solution[0:6])\n",
    "    num_units_bits = BitArray(ga_individual_solution[6:]) \n",
    "    window_size = window_size_bits.uint\n",
    "    num_units = num_units_bits.uint\n",
    "    print('\\nWindow Size: ', window_size, ', Num of Units: ', num_units)\n",
    "    \n",
    "    # Segment the train_data based on new window_size; split into train and validation (80/20)\n",
    "    X,Y = load_cifar10_data(train_data,window_size)\n",
    "    X_train, X_val, y_train, y_val = split(X, Y, test_size = 0.20, random_state = 1120)\n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    inputs = Input(shape=(window_size,1))\n",
    "    x = LSTM(num_units, input_shape=(window_size,1))(inputs)\n",
    "    predictions = Dense(1, activation='linear')(x)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=10,shuffle=True)\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate the RMSE score as fitness score for GA\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    print('Validation RMSE: ', rmse,'\\n')\n",
    "    \n",
    "    return rmse,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import array\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "import pprint\n",
    "\n",
    "JSON_PATH = \"/home/collin/Desktop/EA/\"\n",
    "\n",
    "with open(JSON_PATH+\"vgg16.json\", \"r\") as network_data:\n",
    "    network = json.load(network_data)\n",
    "\n",
    "layer_data = network[\"layers\"]\n",
    "\n",
    "# We want to maximize accuracy\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, typecode='i', fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Initialize with json file\n",
    "def initPopulation(pcls, ind_init, filename):\n",
    "    with open(filename, \"r\") as pop_file:\n",
    "        contents = json.load(pop_file)\n",
    "    return pcls(ind_init(c) for c in contents)\n",
    "\n",
    "def initIndividual(icls, content):\n",
    "    return icls(content)\n",
    "\n",
    "# Instantiate the initializers from json file\n",
    "toolbox.register(\"individual_guess\", initIndividual, creator.Individual)\n",
    "toolbox.register(\"population_guess\", initPopulation, list, toolbox.individual_guess, JSON_PATH+\"vgg16.json\")\n",
    "\n",
    "population = toolbox.population_guess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 4\n",
    "num_generations = 4\n",
    "gene_length = 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
