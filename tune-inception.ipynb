{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# based on https://flyyufelix.github.io/2016/10/08/fine-tuning-in-keras-part2.html\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cifar10 data\n",
    "nb_train_samples = 3000 # 3000 training samples\n",
    "nb_valid_samples = 100 # 100 validation samples\n",
    "num_classes = 10\n",
    "\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_classes = 10\n",
    "\n",
    "def load_cifar10_data(img_rows, img_cols):\n",
    "    # Load cifar10 training and validation sets\n",
    "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
    "\n",
    "    # Resize trainging images\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        X_train = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "    else:\n",
    "        X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "\n",
    "    # Transform targets to keras compatible format\n",
    "    Y_train = np_utils.to_categorical(Y_train[:nb_train_samples], num_classes)\n",
    "    Y_valid = np_utils.to_categorical(Y_valid[:nb_valid_samples], num_classes)\n",
    "\n",
    "    return X_train, Y_train, X_valid, Y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json, load_model\n",
    "# temporary value to hold while we debug\n",
    "i = 0\n",
    "\n",
    "# 1) decodes the algorithm solution to get hyperparameters\n",
    "# 2) trains the individual model\n",
    "# 3) calculates fitness function on validation set and returns fitness score\n",
    "def train_evaluate(ga_individual_solution):   \n",
    "    # Load individual solution from json guess format\n",
    "    print(type(ga_individual_solution))\n",
    "    pprint.pprint(ga_individual_solution)\n",
    "    \n",
    "    # Segment the train_data based on new window_size; split into train and validation (80/20)\n",
    "    #X,Y = load_cifar10_data(train_data,window_size)\n",
    "    #X_train, X_val, y_train, y_val = split(X, Y, test_size = 0.20, random_state = 1120)\n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    #inputs = Input(shape=(window_size,1))\n",
    "    #x = LSTM(num_units, input_shape=(window_size,1))(inputs)\n",
    "    #predictions = Dense(1, activation='linear')(x)\n",
    "    #model = Model(inputs=inputs, outputs=predictions)\n",
    "    #model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    #model.fit(X_train, y_train, epochs=5, batch_size=10,shuffle=True)\n",
    "    #y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate the RMSE score as fitness score for GA\n",
    "    #rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    \n",
    "    global i\n",
    "    i = i+1\n",
    "    print('Validation Fitness Function: ', i,'\\n')\n",
    "    \n",
    "    return i,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'deap.creator.Individual'>\n",
      "['l', 'a', 'y', 'e', 'r', 's']\n",
      "Validation Fitness Function:  1 \n",
      "\n",
      "<class 'deap.creator.Individual'>\n",
      "['n', 'a', 'm', 'e']\n",
      "Validation Fitness Function:  2 \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7d86a5ddae13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation_guess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m r = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.1, \n\u001b[0;32m---> 50\u001b[0;31m ngen = num_generations, verbose = False)\n\u001b[0m",
      "\u001b[0;32m~/p3env/lib/python3.5/site-packages/deap/algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[0;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Vary the pool of individuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0moffspring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvarAnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffspring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcxpb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutpb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# Evaluate the individuals with an invalid fitness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3env/lib/python3.5/site-packages/deap/algorithms.py\u001b[0m in \u001b[0;36mvarAnd\u001b[0;34m(population, toolbox, cxpb, mutpb)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcxpb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             offspring[i - 1], offspring[i] = toolbox.mate(offspring[i - 1],\n\u001b[0;32m---> 74\u001b[0;31m                                                           offspring[i])\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0moffspring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffspring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3env/lib/python3.5/site-packages/deap/tools/crossover.py\u001b[0m in \u001b[0;36mcxOrdered\u001b[0;34m(ind1, ind2)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mholes1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0mholes2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import array\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "\n",
    "import pprint\n",
    "\n",
    "JSON_PATH = \"/home/collin/Desktop/EA/evnet/model-json/\"\n",
    "\n",
    "with open(JSON_PATH+\"vgg16.json\", \"r\") as network_data:\n",
    "    network = json.load(network_data)\n",
    "\n",
    "layer_data = network[\"layers\"]\n",
    "\n",
    "# We want to maximize accuracy\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, typecode='i', fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Initialize with json file\n",
    "def initPopulation(pcls, ind_init, filename):\n",
    "    with open(filename, \"r\") as pop_file:\n",
    "        contents = json.load(pop_file)\n",
    "    return pcls(ind_init(c) for c in contents)\n",
    "\n",
    "def initIndividual(icls, content):\n",
    "    return icls(content)\n",
    "\n",
    "\n",
    "population_size = 4\n",
    "num_generations = 10\n",
    "\n",
    "# Instantiate the initializers from json file\n",
    "toolbox.register(\"individual_guess\", initIndividual, creator.Individual)\n",
    "toolbox.register(\"population_guess\", initPopulation, list, toolbox.individual_guess, JSON_PATH+\"vgg16.json\")\n",
    "\n",
    "toolbox.register('mate', tools.cxOrdered)\n",
    "toolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\n",
    "toolbox.register('select', tools.selRoulette)\n",
    "toolbox.register('evaluate', train_evaluate)\n",
    "\n",
    "population = toolbox.population_guess()\n",
    "r = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.1, \n",
    "ngen = num_generations, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top N solutions\n",
    "best_individuals = tools.selBest(population,k = 2)\n",
    "print('\\nMost fit are: ')\n",
    "for bi in best_individuals:\n",
    "    print('\\n me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using best configuration on complete training set \n",
    "#and make predictions on the test set\n",
    "X_train, y_train, X_test, y_test = load_cifar10_data(test_data,best_window_size)\n",
    "\n",
    "inputs = Input(shape=(best_window_size,1))\n",
    "x = LSTM(best_num_units, input_shape=(best_window_size,1))(inputs)\n",
    "predictions = Dense(1, activation='linear')(x)\n",
    "model = Model(inputs = inputs, outputs = predictions)\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=10,shuffle=True)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Test RMSE: ', rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
