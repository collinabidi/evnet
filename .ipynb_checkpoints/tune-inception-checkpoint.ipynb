{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# based on https://flyyufelix.github.io/2016/10/08/fine-tuning-in-keras-part2.html\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cifar10 data\n",
    "nb_train_samples = 3000 # 3000 training samples\n",
    "nb_valid_samples = 100 # 100 validation samples\n",
    "num_classes = 10\n",
    "\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_classes = 10\n",
    "\n",
    "def load_cifar10_data(img_rows, img_cols):\n",
    "    # Load cifar10 training and validation sets\n",
    "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
    "\n",
    "    # Resize trainging images\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        X_train = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "    else:\n",
    "        X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "\n",
    "    # Transform targets to keras compatible format\n",
    "    Y_train = np_utils.to_categorical(Y_train[:nb_train_samples], num_classes)\n",
    "    Y_valid = np_utils.to_categorical(Y_valid[:nb_valid_samples], num_classes)\n",
    "\n",
    "    return X_train, Y_train, X_valid, Y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json, load_model\n",
    "# temporary value to hold while we debug\n",
    "i = 0\n",
    "\n",
    "# 1) decodes the algorithm solution to get hyperparameters\n",
    "# 2) trains the individual model\n",
    "# 3) calculates fitness function on validation set and returns fitness score\n",
    "def train_evaluate(ga_individual_solution):   \n",
    "    # Load individual solution from json guess format\n",
    "    print(type(ga_individual_solution))\n",
    "    pprint.pprint(ga_individual_solution)\n",
    "    \n",
    "    # Segment the train_data based on new window_size; split into train and validation (80/20)\n",
    "    X,Y = load_cifar10_data(train_data,window_size)\n",
    "    X_train, X_val, y_train, y_val = split(X, Y, test_size = 0.20, random_state = 1120)\n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    #inputs = Input(shape=(window_size,1))\n",
    "    #x = LSTM(num_units, input_shape=(window_size,1))(inputs)\n",
    "    #predictions = Dense(1, activation='linear')(x)\n",
    "    #model = Model(inputs=inputs, outputs=predictions)\n",
    "    #model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    #model.fit(X_train, y_train, epochs=5, batch_size=10,shuffle=True)\n",
    "    #y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate the RMSE score as fitness score for GA\n",
    "    #rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    print('Validation Fitness Function: ', i,'\\n')\n",
    "    i = i+1\n",
    "    \n",
    "    return i,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the first argument must be callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-28704b5ad2cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation_guess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"population\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcxOrdered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3env/lib/python3.5/site-packages/deap/base.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, alias, function, *args, **kargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mpfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mpfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mpfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: the first argument must be callable"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import array\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "import pprint\n",
    "\n",
    "JSON_PATH = \"/home/collin/Desktop/EA/evnet/model-json/\"\n",
    "\n",
    "with open(JSON_PATH+\"vgg16.json\", \"r\") as network_data:\n",
    "    network = json.load(network_data)\n",
    "\n",
    "layer_data = network[\"layers\"]\n",
    "\n",
    "# We want to maximize accuracy\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, typecode='i', fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Initialize with json file\n",
    "def initPopulation(pcls, ind_init, filename):\n",
    "    with open(filename, \"r\") as pop_file:\n",
    "        contents = json.load(pop_file)\n",
    "    return pcls(ind_init(c) for c in contents)\n",
    "\n",
    "def initIndividual(icls, content):\n",
    "    return icls(content)\n",
    "\n",
    "\n",
    "population_size = 4\n",
    "num_generations = 10\n",
    "\n",
    "# Instantiate the initializers from json file\n",
    "toolbox.register(\"individual_guess\", initIndividual, creator.Individual)\n",
    "toolbox.register(\"population_guess\", initPopulation, list, toolbox.individual_guess, JSON_PATH+\"vgg16.json\")\n",
    "\n",
    "toolbox.register('mate', tools.cxOrdered)\n",
    "toolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\n",
    "toolbox.register('select', tools.selRoulette)\n",
    "toolbox.register('evaluate', train_evaluate)\n",
    "\n",
    "population = toolbox.population_guess(n = population_size)\n",
    "r = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.1, \n",
    "ngen = num_generations, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top N solutions\n",
    "best_individuals = tools.selBest(population,k = 2)\n",
    "print('\\nMost fit are: ')\n",
    "for bi in best_individuals:\n",
    "    print('\\n me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using best configuration on complete training set \n",
    "#and make predictions on the test set\n",
    "X_train, y_train, X_test, y_test = load_cifar10_data(test_data,best_window_size)\n",
    "\n",
    "inputs = Input(shape=(best_window_size,1))\n",
    "x = LSTM(best_num_units, input_shape=(best_window_size,1))(inputs)\n",
    "predictions = Dense(1, activation='linear')(x)\n",
    "model = Model(inputs = inputs, outputs = predictions)\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=10,shuffle=True)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Test RMSE: ', rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
